[
  {
    "id": 16,
    "title": "A mathematical framework for transformer circuits",
    "tags": [],
    "primaryTag": "Techniques/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "blog": "https://transformer-circuits.pub/2021/framework/index.html"
    }
  },
  {
    "id": 17,
    "title": "Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models",
    "tags": [],
    "primaryTag": "Techniques/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2401": "http://arxiv.org/abs/2401.06102"
    }
  },
  {
    "id": 18,
    "title": "interpreting GPT: the logit lens",
    "tags": [],
    "primaryTag": "Techniques/Embedding Projection",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Lesswrong 2020": "https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens"
    }
  },
  {
    "id": 19,
    "title": "Analyzing Transformers in Embedding Space",
    "tags": [],
    "primaryTag": "Techniques/Embedding Projection",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ACL 2023": "https://aclanthology.org/2023.acl-long.893"
    }
  },
  {
    "id": 20,
    "title": "Eliciting Latent Predictions from Transformers with the Tuned Lens",
    "tags": [],
    "primaryTag": "Techniques/Embedding Projection",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2303": "https://arxiv.org/abs/2303.08112"
    }
  },
  {
    "id": 21,
    "title": "An Adversarial Example for Direct Logit Attribution: Memory Management in gelu-4l",
    "tags": [],
    "primaryTag": "Techniques/Embedding Projection",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2310": "http://arxiv.org/abs/2310.07325"
    }
  },
  {
    "id": 22,
    "title": "Future Lens: Anticipating Subsequent Tokens from a Single Hidden State",
    "tags": [],
    "primaryTag": "Techniques/Embedding Projection",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "CoNLL 2023": "https://aclanthology.org/2023.conll-1.37/"
    }
  },
  {
    "id": 23,
    "title": "SelfIE: Self-Interpretation of Large Language Model Embeddings",
    "tags": [],
    "primaryTag": "Techniques/Embedding Projection",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.10949"
    }
  },
  {
    "id": 24,
    "title": "InversionView: A General-Purpose Method for Reading Information from Neural Activations",
    "tags": [],
    "primaryTag": "Techniques/Embedding Projection",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=P7MW0FahEq"
    }
  },
  {
    "id": 25,
    "title": "Enhancing Neural Network Transparency through Representation Analysis",
    "tags": [],
    "primaryTag": "Techniques/Probing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2310": "https://arxiv.org/abs/2310.01405",
      "openreview": "https://openreview.net/forum?id=aCgybhcZFi"
    }
  },
  {
    "id": 26,
    "title": "Analyzing And Editing Inner Mechanisms of Backdoored Language Models",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2303": "http://arxiv.org/abs/2302.12461"
    }
  },
  {
    "id": 27,
    "title": "Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2303": "https://arxiv.org/abs/2303.02536"
    }
  },
  {
    "id": 28,
    "title": "Localizing Model Behavior with Path Patching",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2304": "https://arxiv.org/abs/2304.05969"
    }
  },
  {
    "id": 29,
    "title": "Interpretability at Scale: Identifying Causal Mechanisms in Alpaca",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "NIPS 2023": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/f6a8b109d4d4fd64c75e94aaf85d9697-Abstract-Conference.html"
    }
  },
  {
    "id": 30,
    "title": "Towards Best Practices of Activation Patching in Language Models: Metrics and Methods",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=Hf17y6u9BC"
    }
  },
  {
    "id": 31,
    "title": "Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=Ebt7JgMHv1"
    }
  },
  {
    "id": 32,
    "title": "A Reply to Makelov et al. (2023)'s \"Interpretability Illusion\" Arguments",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2401": "https://arxiv.org/abs/2401.12631"
    }
  },
  {
    "id": 33,
    "title": "CausalGym: Benchmarking causal interpretability methods on linguistic tasks",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.12560"
    }
  },
  {
    "id": 34,
    "title": "How to use and interpret activation patching",
    "tags": [],
    "primaryTag": "Techniques/Causal Intervention",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2404": "http://arxiv.org/abs/2404.15255"
    }
  },
  {
    "id": 35,
    "title": "Towards Automated Circuit Discovery for Mechanistic Interpretability",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "NIPS 2023": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/34e1dbe95d34d7ebaf99b9bcaeb5b2be-Abstract-Conference.html"
    }
  },
  {
    "id": 36,
    "title": "Neuron to Graph: Interpreting Language Model Neurons at Scale",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2305": "https://arxiv.org/abs/2305.19911",
      "openreview": "https://openreview.net/forum?id=JBLHIR8kBZ"
    }
  },
  {
    "id": 37,
    "title": "Discovering Variable Binding Circuitry with Desiderata",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2307": "http://arxiv.org/abs/2307.03637"
    }
  },
  {
    "id": 38,
    "title": "Discovering Knowledge-Critical Subnetworks in Pretrained Language Models",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=Mkdwvl3Y8L"
    }
  },
  {
    "id": 39,
    "title": "Attribution Patching Outperforms Automated Circuit Discovery",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2310": "https://arxiv.org/abs/2310.10348"
    }
  },
  {
    "id": 40,
    "title": "AtP*: An efficient and scalable method for localizing LLM behaviour to components",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.00745"
    }
  },
  {
    "id": 41,
    "title": "Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "http://arxiv.org/abs/2403.17806"
    }
  },
  {
    "id": 42,
    "title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.19647"
    }
  },
  {
    "id": 43,
    "title": "Automatically Identifying Local and Global Circuits with Linear Computation Graphs",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2405": "https://arxiv.org/abs/2405.13868"
    }
  },
  {
    "id": 44,
    "title": "Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2405": "http://arxiv.org/abs/2405.12522"
    }
  },
  {
    "id": 45,
    "title": "Hypothesis Testing the Circuit Hypothesis in LLMs",
    "tags": [],
    "primaryTag": "Techniques/Automation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=ibSNv9cldu"
    }
  },
  {
    "id": 46,
    "title": "Towards monosemanticity: Decomposing language models with dictionary learning",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Transformer Circuits Thread": "https://transformer-circuits.pub/2023/monosemantic-features"
    }
  },
  {
    "id": 47,
    "title": "Sparse Autoencoders Find Highly Interpretable Features in Language Models",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=F76bwRSLeK"
    }
  },
  {
    "id": 48,
    "title": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Alignment Forum": "https://www.alignmentforum.org/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream"
    }
  },
  {
    "id": 49,
    "title": "Attention SAEs Scale to GPT-2 Small",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Alignment Forum": "https://www.alignmentforum.org/posts/FSTRedtjuHa4Gfdbr/attention-saes-scale-to-gpt-2-small"
    }
  },
  {
    "id": 50,
    "title": "We Inspected Every Head In GPT-2 Small using SAEs So You Don't Have To",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Alignment Forum": "https://www.alignmentforum.org/posts/xmegeW5mqiBsvoaim/we-inspected-every-head-in-gpt-2-small-using-saes-so-you-don"
    }
  },
  {
    "id": 51,
    "title": "Understanding SAE Features with the Logit Lens",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Alignment Forum": "https://www.alignmentforum.org/posts/qykrYY6rXXM7EEs8Q/understanding-sae-features-with-the-logit-lens"
    }
  },
  {
    "id": 52,
    "title": "Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Transformer Circuits Thread": "https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html"
    }
  },
  {
    "id": 53,
    "title": "Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2405": "http://arxiv.org/abs/2405.12522"
    }
  },
  {
    "id": 54,
    "title": "Scaling and evaluating sparse autoencoders",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2406": "https://arxiv.org/abs/2406.04093",
      "code": "https://github.com/openai/sparse_autoencoder/"
    }
  },
  {
    "id": 55,
    "title": "Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=qzsDKwGJyB"
    }
  },
  {
    "id": 56,
    "title": "Sparse Autoencoders Match Supervised Features for Model Steering on the IOI Task",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=JdrVuEQih5"
    }
  },
  {
    "id": 57,
    "title": "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=bcV7rhBEcM"
    }
  },
  {
    "id": 58,
    "title": "Transcoders find interpretable LLM feature circuits",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=GWqzUR2dOX"
    }
  },
  {
    "id": 59,
    "title": "Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2407": "http://arxiv.org/abs/2407.14435"
    }
  },
  {
    "id": 60,
    "title": "Sparse Autoencoders Reveal Temporal Difference Learning in Large Language Models",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.01280"
    }
  },
  {
    "id": 61,
    "title": "Mechanistic Permutability: Match Features Across Layers",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.07656"
    }
  },
  {
    "id": 62,
    "title": "Sparse Autoencoders Reveal Universal Feature Spaces Across Large Language Models",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.06981"
    }
  },
  {
    "id": 63,
    "title": "Investigating Sensitive Directions in GPT-2: An Improved Baseline and Comparative Analysis of SAEs",
    "tags": [],
    "primaryTag": "Techniques/Sparse Coding",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.12555"
    }
  },
  {
    "id": 64,
    "title": "Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT",
    "tags": [],
    "primaryTag": "Techniques/Visualization",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2305": "[10.48550/arXiv.2305.13417](http://arxiv.org/abs/2305.13417)",
      "github": "https://github.com/shacharKZ/Visualizing-the-Information-Flow-of-GPT"
    }
  },
  {
    "id": 65,
    "title": "Sparse AutoEncoder Visulization",
    "tags": [],
    "primaryTag": "Techniques/Visualization",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "github": "https://github.com/callummcdougall/sae_vis"
    }
  },
  {
    "id": 66,
    "title": "SAE-VIS: Announcement Post",
    "tags": [],
    "primaryTag": "Techniques/Visualization",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "lesswrong": "https://www.lesswrong.com/posts/nAhy6ZquNY7AD3RkD/sae-vis-announcement-post-1"
    }
  },
  {
    "id": 67,
    "title": "LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models",
    "tags": [],
    "primaryTag": "Techniques/Visualization",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2404": "http://arxiv.org/abs/2404.07004",
      "github": "https://github.com/facebookresearch/ llm-transparency-tool"
    }
  },
  {
    "id": 68,
    "title": "Tracr: Compiled Transformers as a Laboratory for Interpretability",
    "tags": [],
    "primaryTag": "Techniques/Translation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2301": "http://arxiv.org/abs/2301.05062"
    }
  },
  {
    "id": 69,
    "title": "Opening the AI black box: program synthesis via mechanistic interpretability",
    "tags": [],
    "primaryTag": "Techniques/Translation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.05110"
    }
  },
  {
    "id": 70,
    "title": "An introduction to graphical tensor notation for mechanistic interpretability",
    "tags": [],
    "primaryTag": "Techniques/Translation",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.01790"
    }
  },
  {
    "id": 71,
    "title": "Look Before You Leap: A Universal Emergent Decomposition of Retrieval Tasks in Language Models",
    "tags": [],
    "primaryTag": "Techniques/Benchmark",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "http://arxiv.org/abs/2312.10091"
    }
  },
  {
    "id": 72,
    "title": "RAVEL: Evaluating Interpretability Methods on Disentangling Language Model Representations",
    "tags": [],
    "primaryTag": "Techniques/Benchmark",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.17700"
    }
  },
  {
    "id": 73,
    "title": "Towards Principled Evaluations of Sparse Autoencoders for Interpretability and Control",
    "tags": [],
    "primaryTag": "Techniques/Benchmark",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2405": "http://arxiv.org/abs/2405.08366"
    }
  },
  {
    "id": 74,
    "title": "InterpBench: Semi-Synthetic Transformers for Evaluating Mechanistic Interpretability Techniques",
    "tags": [],
    "primaryTag": "Techniques/Benchmark",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2407": "http://arxiv.org/abs/2407.14494"
    }
  },
  {
    "id": 75,
    "title": "Circuit Component Reuse Across Tasks in Transformer Language Models",
    "tags": [],
    "primaryTag": "Ability/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024 spotlight": "https://openreview.net/forum?id=fpoAYV6Wsk"
    }
  },
  {
    "id": 76,
    "title": "Towards Universality: Studying Mechanistic Similarity Across Language Model Architectures",
    "tags": [],
    "primaryTag": "Ability/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxvi 2410": "https://arxiv.org/abs/2410.06672"
    }
  },
  {
    "id": 77,
    "title": "From Tokens to Words: On the Inner Lexicon of LLMs",
    "tags": [],
    "primaryTag": "Ability/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.05864"
    }
  },
  {
    "id": 78,
    "title": "Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models",
    "tags": [],
    "primaryTag": "Ability/Reasoning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "EMNLP 2023": "https://aclanthology.org/2023.emnlp-main.299"
    }
  },
  {
    "id": 79,
    "title": "How Large Language Models Implement Chain-of-Thought?",
    "tags": [],
    "primaryTag": "Ability/Reasoning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=b2XfOm3RJa"
    }
  },
  {
    "id": 80,
    "title": "Do Large Language Models Latently Perform Multi-Hop Reasoning?",
    "tags": [],
    "primaryTag": "Ability/Reasoning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.16837"
    }
  },
  {
    "id": 81,
    "title": "How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning",
    "tags": [],
    "primaryTag": "Ability/Reasoning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.18312"
    }
  },
  {
    "id": 82,
    "title": "Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning",
    "tags": [],
    "primaryTag": "Ability/Reasoning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.18344"
    }
  },
  {
    "id": 83,
    "title": "Iteration Head: A Mechanistic Study of Chain-of-Thought",
    "tags": [],
    "primaryTag": "Ability/Reasoning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2406": "https://arxiv.org/abs/2406.02128"
    }
  },
  {
    "id": 84,
    "title": "From Sparse Dependence to Sparse Attention: Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency",
    "tags": [],
    "primaryTag": "Ability/Reasoning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.05459"
    }
  },
  {
    "id": 85,
    "title": "Interpretability in the wild: a circuit for indirect object identification in GPT-2 small",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2023": "https://openreview.net/forum?id=NpsVSN6o4ul"
    }
  },
  {
    "id": 86,
    "title": "Entity Tracking in Language Models",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ACL 2023": "https://aclanthology.org/2023.acl-long.213"
    }
  },
  {
    "id": 87,
    "title": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "NIPS 2023": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/efbba7719cc5172d175240f24be11280-Abstract-Conference.html"
    }
  },
  {
    "id": 88,
    "title": "Can Transformers Learn to Solve Problems Recursively?",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2305": "http://arxiv.org/abs/2305.14699"
    }
  },
  {
    "id": 89,
    "title": "Analyzing And Editing Inner Mechanisms of Backdoored Language Models",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "NeurIPS 2023 Workshop": "https://openreview.net/forum?id=e9F4fB23o0"
    }
  },
  {
    "id": 90,
    "title": "Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2307": "http://arxiv.org/abs/2307.09458"
    }
  },
  {
    "id": 91,
    "title": "Refusal mechanisms: initial experiments with Llama-2-7b-chat",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "AlignmentForum 2312": "https://www.alignmentforum.org/posts/pYcEhoAoPfHhgJ8YC/refusal-mechanisms-initial-experiments-with-llama-2-7b-chat"
    }
  },
  {
    "id": 92,
    "title": "Forbidden Facts: An Investigation of Competing Objectives in Llama-2",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "http://arxiv.org/abs/2312.08793"
    }
  },
  {
    "id": 93,
    "title": "How do Language Models Bind Entities in Context?",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=zb3b6oKO77"
    }
  },
  {
    "id": 94,
    "title": "How Language Models Learn Context-Free Grammars?",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=qnbLGV9oFL"
    }
  },
  {
    "id": 95,
    "title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2401": "http://arxiv.org/abs/2401.01967"
    }
  },
  {
    "id": 96,
    "title": "Do Llamas Work in English? On the Latent Language of Multilingual Transformers",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.10588"
    }
  },
  {
    "id": 97,
    "title": "Evidence of Learned Look-Ahead in a Chess-Playing Neural Network",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv2406": "https://arxiv.org/abs/2406.00877"
    }
  },
  {
    "id": 98,
    "title": "How much do contextualized representations encode long-range context?",
    "tags": [],
    "primaryTag": "Ability/Function",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.12292"
    }
  },
  {
    "id": 99,
    "title": "Progress measures for grokking via mechanistic interpretability",
    "tags": [],
    "primaryTag": "Ability/Arithmetic",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2023": "https://openreview.net/forum?id=9XFSbDPmdW"
    }
  },
  {
    "id": 100,
    "title": "A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2023": "https://openreview.net/forum?id=jCOrkuUpss"
    }
  },
  {
    "id": 101,
    "title": "The Mechanistic Basis of Data Dependence and Abrupt Learning in an In-Context Classification Task",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024 oral": "https://openreview.net/forum?id=aN4Jf6Cx69"
    }
  },
  {
    "id": 102,
    "title": "Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024 spotlight": "https://openreview.net/forum?id=MO5PiKHELW"
    }
  },
  {
    "id": 103,
    "title": "A simple and interpretable model of grokking modular arithmetic tasks",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=0ZUKLCxwBo"
    }
  },
  {
    "id": 104,
    "title": "Unified View of Grokking, Double Descent and Emergent Abilities: A Perspective from Circuits Competition",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.15175"
    }
  },
  {
    "id": 105,
    "title": "Interpreting Grokked Transformers in Complex Modular Arithmetic",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.16726"
    }
  },
  {
    "id": 106,
    "title": "Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.19465"
    }
  },
  {
    "id": 107,
    "title": "Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2406": "https://arxiv.org/abs/2406.02550"
    }
  },
  {
    "id": 108,
    "title": "Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization",
    "tags": [],
    "primaryTag": "Learning Dynamics/Phase Transition",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=ns8IH5Sn5y"
    }
  },
  {
    "id": 109,
    "title": "Studying Large Language Model Generalization with Influence Functions",
    "tags": [],
    "primaryTag": "Learning Dynamics/Fine-tuning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2308": "http://arxiv.org/abs/2308.03296"
    }
  },
  {
    "id": 110,
    "title": "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks",
    "tags": [],
    "primaryTag": "Learning Dynamics/Fine-tuning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=A0HKeKl4Nl"
    }
  },
  {
    "id": 111,
    "title": "Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking",
    "tags": [],
    "primaryTag": "Learning Dynamics/Fine-tuning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=8sKcAWOf2D"
    }
  },
  {
    "id": 112,
    "title": "The Hidden Space of Transformer Language Adapters",
    "tags": [],
    "primaryTag": "Learning Dynamics/Fine-tuning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.13137"
    }
  },
  {
    "id": 113,
    "title": "Dissecting Fine-Tuning Unlearning in Large Language Models",
    "tags": [],
    "primaryTag": "Learning Dynamics/Fine-tuning",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "EMNLP 2024": "https://arxiv.org/abs/2410.06606"
    }
  },
  {
    "id": 114,
    "title": "Implicit Representations of Meaning in Neural Language Models",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ACL 2021": "https://aclanthology.org/2021.acl-long.143"
    }
  },
  {
    "id": 115,
    "title": "All Roads Lead to Rome? Exploring the Invariance of Transformers' Representations",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2305": "http://arxiv.org/abs/2305.14555"
    }
  },
  {
    "id": 116,
    "title": "Observable Propagation: Uncovering Feature Vectors in Transformers",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=sNWQUTkDmA"
    }
  },
  {
    "id": 117,
    "title": "In-Context Learning in Large Language Models: A Neuroscience-inspired Analysis of Representations",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=UEdS2lIgfY"
    }
  },
  {
    "id": 118,
    "title": "Challenges with unsupervised LLM knowledge discovery",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "https://arxiv.org/abs/2312.10029"
    }
  },
  {
    "id": 119,
    "title": "Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2307": "http://arxiv.org/abs/2307.00175"
    }
  },
  {
    "id": 120,
    "title": "Position Paper: Toward New Frameworks for Studying Model Representations",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.03855"
    }
  },
  {
    "id": 121,
    "title": "How Large Language Models Encode Context Knowledge? A Layer-Wise Probing Study",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.16061"
    }
  },
  {
    "id": 122,
    "title": "More than Correlation: Do Large Language Models Learn Causal Representations of Space",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "https://arxiv.org/abs/2312.16257"
    }
  },
  {
    "id": 123,
    "title": "Do Large Language Models Mirror Cognitive Language Processing?",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.18023"
    }
  },
  {
    "id": 124,
    "title": "On the Scaling Laws of Geographical Representation in Language Models",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.19406"
    }
  },
  {
    "id": 125,
    "title": "Monotonic Representation of Numeric Properties in Language Models",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "http://arxiv.org/abs/2403.10381"
    }
  },
  {
    "id": 126,
    "title": "Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2404": "http://arxiv.org/abs/2404.07066"
    }
  },
  {
    "id": 127,
    "title": "Simple probes can catch sleeper agents",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Anthropic Blog": "https://www.anthropic.com/research/probes-catch-sleeper-agents"
    }
  },
  {
    "id": 128,
    "title": "PaCE: Parsimonious Concept Engineering for Large Language Models",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2406": "https://arxiv.org/abs/2406.04331"
    }
  },
  {
    "id": 129,
    "title": "The Geometry of Categorical and Hierarchical Concepts in Large Language Models",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=KXuYjuBzKo"
    }
  },
  {
    "id": 130,
    "title": "Concept Space Alignment in Multilingual LLMs",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "EMNLP 2024": "https://arxiv.org/abs/2410.01079"
    }
  },
  {
    "id": 131,
    "title": "Sparse Autoencoders Reveal Universal Feature Spaces Across Large Language Models",
    "tags": [],
    "primaryTag": "Representation/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.06981"
    }
  },
  {
    "id": 132,
    "title": "Actually, Othello-GPT Has A Linear Emergent World Representation",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Neel Nanda's blog": "https://www.neelnanda.io/mechanistic-interpretability/othello"
    }
  },
  {
    "id": 133,
    "title": "Language Models Linearly Represent Sentiment",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=iGDWZFc7Ya"
    }
  },
  {
    "id": 134,
    "title": "Language Models Represent Space and Time",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=jE8xbmvFin"
    }
  },
  {
    "id": 135,
    "title": "The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "openreview": "https://openreview.net/forum?id=CeJEfNKstt"
    }
  },
  {
    "id": 136,
    "title": "Linearity of Relation Decoding in Transformer Language Models",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=w7LU2s14kE"
    }
  },
  {
    "id": 137,
    "title": "The Linear Representation Hypothesis and the Geometry of Large Language Models",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2311": "https://arxiv.org/abs/2311.03658"
    }
  },
  {
    "id": 138,
    "title": "Language Models Represent Beliefs of Self and Others",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.18496"
    }
  },
  {
    "id": 139,
    "title": "On the Origins of Linear Representations in Large Language Models",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "http://arxiv.org/abs/2403.03867"
    }
  },
  {
    "id": 140,
    "title": "Refusal in LLMs is mediated by a single direction",
    "tags": [],
    "primaryTag": "Representation/Linearity",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "Lesswrong 2024": "https://www.lesswrong.com/posts/jGuXSZgv6qfdhMCuJ/refusal-in-llms-is-mediated-by-a-single-direction"
    }
  },
  {
    "id": 141,
    "title": "Aligning Large Language Models with Human Preferences through Representation Engineering",
    "tags": [],
    "primaryTag": "Application/Training",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv2312": "http://arxiv.org/abs/2312.15997"
    }
  },
  {
    "id": 142,
    "title": "ReFT: Representation Finetuning for Language Models",
    "tags": [],
    "primaryTag": "Application/Training",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2404": "https://arxiv.org/abs/2404.03592",
      "github": "https://github.com/stanfordnlp/pyreft"
    }
  },
  {
    "id": 143,
    "title": "Direct Preference Optimization Using Sparse Feature-Level Constraints",
    "tags": [],
    "primaryTag": "Application/Training",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv2411": "https://arxiv.org/abs/2411.07618"
    }
  },
  {
    "id": 144,
    "title": "LLM Pretraining with Continuous Concepts",
    "tags": [],
    "primaryTag": "Application/Training",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv2502": "https://arxiv.org/abs/2502.08524"
    }
  },
  {
    "id": 145,
    "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "NIPS 2023": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/81b8390039b7302c909cb769f8b6cd93-Abstract-Conference.html",
      "github": "https://github.com/likenneth/honest_llama"
    }
  },
  {
    "id": 146,
    "title": "Activation Addition: Steering Language Models Without Optimization",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2308": "http://arxiv.org/abs/2308.10248"
    }
  },
  {
    "id": 147,
    "title": "Self-Detoxifying Language Models via Toxification Reversal",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "EMNLP 2023": "https://aclanthology.org/2023.emnlp-main.269"
    }
  },
  {
    "id": 148,
    "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2309": "https://arxiv.org/abs/2309.03883"
    }
  },
  {
    "id": 149,
    "title": "In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2311": "http://arxiv.org/abs/2311.06668"
    }
  },
  {
    "id": 150,
    "title": "Steering Llama 2 via Contrastive Activation Addition",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "http://arxiv.org/abs/2312.06681"
    }
  },
  {
    "id": 151,
    "title": "A Language Model's Guide Through Latent Space",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.14433"
    }
  },
  {
    "id": 152,
    "title": "Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2311": "https://arxiv.org/abs/2311.09433"
    }
  },
  {
    "id": 153,
    "title": "Extending Activation Steering to Broad Skills and Multiple Behaviours",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.05767"
    }
  },
  {
    "id": 154,
    "title": "Spectral Editing of Activations for Large Language Model Alignment",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2405": "http://arxiv.org/abs/2405.09719"
    }
  },
  {
    "id": 155,
    "title": "Controlling Large Language Model Agents with Entropic Activation Steering",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2406": "https://arxiv.org/abs/2406.00034"
    }
  },
  {
    "id": 156,
    "title": "Analyzing the Generalization and Reliability of Steering Vectors",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=akCsMk4dDL"
    }
  },
  {
    "id": 157,
    "title": "Towards Inference-time Category-wise Safety Steering for Large Language Models",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.01174"
    }
  },
  {
    "id": 158,
    "title": "A Timeline and Analysis for Representation Plasticity in Large Language Models",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.06225"
    }
  },
  {
    "id": 159,
    "title": "Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors",
    "tags": [],
    "primaryTag": "Application/Activation Steering",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.12299"
    }
  },
  {
    "id": 160,
    "title": "Locating and Editing Factual Associations in GPT",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "NIPS 2022": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/6f1d43d5a82a37e89b0665b33bf3a182-Abstract-Conference.html",
      "github": "https://github.com/kmeng01/rome"
    }
  },
  {
    "id": 161,
    "title": "Memory-Based Model Editing at Scale",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2022": "https://proceedings.mlr.press/v162/mitchell22a.html"
    }
  },
  {
    "id": 162,
    "title": "Editing models with task arithmetic",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2023": "https://openreview.net/forum?id=6t0Kwf8-jrj"
    }
  },
  {
    "id": 163,
    "title": "Mass-Editing Memory in a Transformer",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2023": "https://openreview.net/forum?id=MkbcAHIYgyS"
    }
  },
  {
    "id": 164,
    "title": "Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ACL 2023 Findings": "https://aclanthology.org/2023.findings-acl.733"
    }
  },
  {
    "id": 165,
    "title": "Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ACL 2023": "https://aclanthology.org/2023.acl-long.300"
    }
  },
  {
    "id": 166,
    "title": "Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "NIPS 2023": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/3927bbdcf0e8d1fa8aa23c26f358a281-Abstract-Conference.html"
    }
  },
  {
    "id": 167,
    "title": "Editing Conceptual Knowledge for Large Language Models",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.06259"
    }
  },
  {
    "id": 168,
    "title": "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2406": "https://arxiv.org/abs/2406.01436"
    }
  },
  {
    "id": 169,
    "title": "Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.06331"
    }
  },
  {
    "id": 170,
    "title": "Keys to Robust Edits: from Theoretical Insights to Practical Advances",
    "tags": [],
    "primaryTag": "Application/Knowledge Editing",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2410": "https://arxiv.org/abs/2410.09338"
    }
  },
  {
    "id": 171,
    "title": "The Internal State of an LLM Knows When It's Lying",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "EMNLP 2023 Findings": "https://arxiv.org/abs/2304.13734"
    }
  },
  {
    "id": 172,
    "title": "Do Androids Know They're Only Dreaming of Electric Sheep?",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "https://arxiv.org/abs/2312.17249"
    }
  },
  {
    "id": 173,
    "title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICLR 2024": "https://openreview.net/forum?id=Zj12nzlQbz"
    }
  },
  {
    "id": 174,
    "title": "TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.17811"
    }
  },
  {
    "id": 175,
    "title": "Characterizing Truthfulness in Large Language Model Generations with Local Intrinsic Dimension",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.18048"
    }
  },
  {
    "id": 176,
    "title": "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.19103"
    }
  },
  {
    "id": 177,
    "title": "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "http://arxiv.org/abs/2403.01548"
    }
  },
  {
    "id": 178,
    "title": "Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.06448"
    }
  },
  {
    "id": 179,
    "title": "Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories",
    "tags": [],
    "primaryTag": "Application/Hallucination",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2406": "https://arxiv.org/abs/2406.00034"
    }
  },
  {
    "id": 180,
    "title": "Not all Layers of LLMs are Necessary during Inference",
    "tags": [],
    "primaryTag": "Application/Redundancy",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "http://arxiv.org/abs/2403.02181"
    }
  },
  {
    "id": 181,
    "title": "ShortGPT: Layers in Large Language Models are More Redundant Than You Expect",
    "tags": [],
    "primaryTag": "Application/Redundancy",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "http://arxiv.org/abs/2403.03853"
    }
  },
  {
    "id": 182,
    "title": "The Unreasonable Ineffectiveness of the Deeper Layers",
    "tags": [],
    "primaryTag": "Application/Redundancy",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "http://arxiv.org/abs/2403.17887"
    }
  },
  {
    "id": 183,
    "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
    "tags": [],
    "primaryTag": "Application/Redundancy",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "ICML 2024 MI Workshop": "https://openreview.net/forum?id=R5unwb9KPc"
    }
  },
  {
    "id": 184,
    "title": "The Hydra Effect: Emergent Self-repair in Language Model Computations",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2307": "https://arxiv.org/abs/2307.15771"
    }
  },
  {
    "id": 185,
    "title": "Unveiling A Core Linguistic Region in Large Language Models",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2310": "http://arxiv.org/abs/2310.14928"
    }
  },
  {
    "id": 186,
    "title": "Exploring the Residual Stream of Transformers",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "http://arxiv.org/abs/2312.12141"
    }
  },
  {
    "id": 187,
    "title": "Characterizing Large Language Model Geometry Solves Toxicity Detection and Generation",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2312": "https://arxiv.org/abs/2312.01648"
    }
  },
  {
    "id": 188,
    "title": "Explorations of Self-Repair in Language Models",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "http://arxiv.org/abs/2402.15390"
    }
  },
  {
    "id": 189,
    "title": "Massive Activations in Large Language Models",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.17762"
    }
  },
  {
    "id": 190,
    "title": "Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2402": "https://arxiv.org/abs/2402.15055"
    }
  },
  {
    "id": 191,
    "title": "Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.01509"
    }
  },
  {
    "id": 192,
    "title": "The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models",
    "tags": [],
    "primaryTag": "Component/General",
    "date": "",
    "authors": [],
    "abstract": "",
    "urls": {
      "arxiv 2403": "https://arxiv.org/abs/2403.01509"
    }
  }
] 